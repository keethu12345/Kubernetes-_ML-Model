{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdRtQD7aOWHjZRyql8iDHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "efe8ac2aee25452ca461047b8dc12983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_963925742e31413eb4a8571f0e5a48dd",
              "IPY_MODEL_5f2b346681324d2a8e96e27c03c04692",
              "IPY_MODEL_3d1c314391d54b5fa77a67dc3b7a6dc7"
            ],
            "layout": "IPY_MODEL_78175f4688104631b1ce86acb344f5e0"
          }
        },
        "963925742e31413eb4a8571f0e5a48dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2fbec6aab3848cb966d69b4aa43d00e",
            "placeholder": "​",
            "style": "IPY_MODEL_19c18a574d17483da0b54fd2dd0bdc32",
            "value": "Uploading the dataset shards: 100%"
          }
        },
        "5f2b346681324d2a8e96e27c03c04692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738a98bff6e04e34be3eae0f4a14ad89",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79e6a5aa05b44431bbacdfbb890e7028",
            "value": 1
          }
        },
        "3d1c314391d54b5fa77a67dc3b7a6dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f36031269664b8dbc57d945f6d4a13e",
            "placeholder": "​",
            "style": "IPY_MODEL_d0e4b0cd7f8b4bd4b83eca32146f99c9",
            "value": " 1/1 [00:01&lt;00:00,  1.33s/it]"
          }
        },
        "78175f4688104631b1ce86acb344f5e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2fbec6aab3848cb966d69b4aa43d00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c18a574d17483da0b54fd2dd0bdc32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "738a98bff6e04e34be3eae0f4a14ad89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79e6a5aa05b44431bbacdfbb890e7028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f36031269664b8dbc57d945f6d4a13e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0e4b0cd7f8b4bd4b83eca32146f99c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0f574705158487c84f7fea2798d1c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c24d741c6714bcc9010b89da6678e87",
              "IPY_MODEL_b0af2c8f923f4d999fae8609ad3ac376",
              "IPY_MODEL_a2cf03f77a8b4dc7889e37f282d2fbd0"
            ],
            "layout": "IPY_MODEL_5e16d4dec18f4c6095f7da5af5bef3bd"
          }
        },
        "5c24d741c6714bcc9010b89da6678e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c158572d56347faabd26947273e5ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_49c013ac21b24e50a354ff587ed8dae5",
            "value": "Creating parquet from Arrow format: 100%"
          }
        },
        "b0af2c8f923f4d999fae8609ad3ac376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f0e70b4f9f54a0eaf124c83337950d7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61851494cd8e447180a07f10f6b73a33",
            "value": 1
          }
        },
        "a2cf03f77a8b4dc7889e37f282d2fbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df8d2879eb4b498584dd296fdeb9f7f1",
            "placeholder": "​",
            "style": "IPY_MODEL_77f589f8753a430195777be571e52684",
            "value": " 1/1 [00:00&lt;00:00, 41.35ba/s]"
          }
        },
        "5e16d4dec18f4c6095f7da5af5bef3bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c158572d56347faabd26947273e5ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c013ac21b24e50a354ff587ed8dae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f0e70b4f9f54a0eaf124c83337950d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61851494cd8e447180a07f10f6b73a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df8d2879eb4b498584dd296fdeb9f7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f589f8753a430195777be571e52684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keethu12345/Kubernetes_ML-Model/blob/main/Kubernetes_Text_Generation_ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data sources identified are the Kubernetes documentation available in https://kubernetes.io/docs/home/.\n",
        "\n",
        "We shall be performing some web scraping over this data and preprocess it for traning using Hugging Face transformers. The dataset will be uploaded to Hugging Face hub as well.\n",
        "\n",
        "1) The first task would be web scraping of the data.\n",
        "\n",
        "2) The second task would be pre-processing the data.\n",
        "\n",
        "After this we shall be fine tuning GPT model over the Kubernetes dataset to generate texts.\n",
        "\n",
        "3) Fine tuning GPT model over Kubernetes Dataset."
      ],
      "metadata": {
        "id": "wJi-5BTzvAP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Web scraping:"
      ],
      "metadata": {
        "id": "56WPu99_vESN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the web scraping purposes we shall be using the Python libraries beautifulsoup4 and requests libraries:"
      ],
      "metadata": {
        "id": "XdcrQZuzvIua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d7AC6HxQpr5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9a6ceee1-a669-401d-b592-ba4e1c6e93e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully scraped data from the following URLs:\n",
            " - https://kubernetes.io/docs/concepts/services-networking/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/service/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/ingress/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/gateway/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/network-policies/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/dual-stack/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/topology-aware-routing/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/windows-networking/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/cluster-ip-allocation/\n",
            " - https://kubernetes.io/docs/concepts/services-networking/service-traffic-policy/\n",
            "\n",
            "Sample of combined text data:\n",
            "\n",
            "Services, Load Balancing, and NetworkingConcepts and resources behind networking in Kubernetes.The Kubernetes network modelEvery Pod in a cluster gets its own unique cluster-wide IP address. This means you do not need to explicitly create links between Pods and you almost never need to deal with mapping container ports to host ports.This creates a clean, backwards-compatible model where Pods can be treated much like VMs or physical hosts from the perspectives of port allocation, naming, service discovery, load balancing, application configuration, and migration.Kubernetes imposes the following fundamental requirements on any networking implementation (barring any intentional network segmentation policies):pods can communicate with all other pods on any other node without NATagents on a node (e.g. system daemons, kubelet) can communicate with all pods on that nodeNote: For those platforms that support Pods running in the host network (e.g. Linux), when pods are attached to the host netw\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def scrape_kubernetes_docs(url):\n",
        "    try:\n",
        "        # Fetch HTML content\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        html_content = response.text\n",
        "\n",
        "        # Parse HTML with BeautifulSoup\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "        # Find relevant sections by inspecting the webpage structure\n",
        "        sections = soup.find_all('div', class_='td-content') or soup.find_all('article')\n",
        "\n",
        "        if not sections:\n",
        "            raise ValueError(\"No content sections found on the page\")\n",
        "\n",
        "        # Extract text from each section\n",
        "        text_data = []\n",
        "        for section in sections:\n",
        "            # Clean text (remove HTML tags, extra spaces, etc.)\n",
        "            cleaned_text = re.sub(r'<.*?>', '', section.get_text())\n",
        "            cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # Remove extra spaces\n",
        "            text_data.append(cleaned_text)\n",
        "\n",
        "        return text_data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching URL: {e}\")\n",
        "    except ValueError as ve:\n",
        "        print(f\"Error: {ve}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "# List of URLs of Kubernetes documentation pages\n",
        "kubernetes_docs_urls = [\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/service/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/ingress/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/gateway/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/network-policies/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/dual-stack/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/topology-aware-routing/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/windows-networking/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/cluster-ip-allocation/',\n",
        "    'https://kubernetes.io/docs/concepts/services-networking/service-traffic-policy/',\n",
        "\n",
        "]\n",
        "\n",
        "# Scrape the documentation from all URLs\n",
        "all_kubernetes_text_data = []\n",
        "for url in kubernetes_docs_urls:\n",
        "    text_data = scrape_kubernetes_docs(url)\n",
        "    if text_data:\n",
        "        all_kubernetes_text_data.extend(text_data)\n",
        "\n",
        "# Combine all scraped text\n",
        "combined_kubernetes_text = \"\\n\\n\".join(all_kubernetes_text_data)\n",
        "\n",
        "# Check if data was successfully scraped\n",
        "if all_kubernetes_text_data:\n",
        "    print(\"Successfully scraped data from the following URLs:\")\n",
        "    for url in kubernetes_docs_urls:\n",
        "        print(f\" - {url}\")\n",
        "    print(\"\\nSample of combined text data:\\n\")\n",
        "    print(combined_kubernetes_text[:1000])  # Print first 1000 characters of combined text\n",
        "else:\n",
        "    print(\"No data scraped. Check your scraping function and the URLs.\")\n",
        "\n",
        "# Optionally, write the combined text to a file for further processing\n",
        "with open('kubernetes_docs.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(combined_kubernetes_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The combined_kebernetes_text file contains the data we have scraped from the kubernetes documentation links as shown above.\n",
        "\n",
        "In the further steps we shall be creating a dataset in the HuggingFace hub, and upload this data into the hub as shown below:"
      ],
      "metadata": {
        "id": "gxx6oPiUvYif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Creation of the *kubernetes-documentation-dataset* Dataset:"
      ],
      "metadata": {
        "id": "LlYY6fuHwI1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j47uGF2-qbLU",
        "outputId": "229bacee-0174-4366-b1d0-895abea592ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jVc2s1cKrGVu",
        "outputId": "245580c8-2168-4675-abe0-f39d029de68a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your kubernetes_docs.txt is in the current directory\n",
        "!ls /content/kubernetes_docs.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VRNJJyTUr7xW",
        "outputId": "cfac0d01-3ee3-4b08-eefd-51e5e27ccc6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/kubernetes_docs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define source and destination paths\n",
        "source_path = '/content/kubernetes_docs.txt'\n",
        "destination_path = '/content/drive/MyDrive/kubernetes_docs.txt'\n",
        "\n",
        "# Copy file from Colab to Google Drive\n",
        "shutil.copy(source_path, destination_path)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "D8gqhD9_sDht",
        "outputId": "25c43e21-0085-4c3d-bdcd-b2d762fef2ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/kubernetes_docs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Create dataset directory\n",
        "dataset_dir = '/content/kubernetes_dataset'\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# Upload your kubernetes_docs.txt to Colab (if not using Google Drive)\n",
        "# Optionally, you can use !cp command to copy from Google Drive\n",
        "!cp /content/kubernetes_docs.txt /content/drive/MyDrive/kubernetes_docs.txt\n",
        "\n",
        "# Example dataset configuration\n",
        "dataset_config = {\n",
        "    \"name\": \"kubernetes_documentation\",\n",
        "    \"description\": \"Text data extracted from Kubernetes documentation pages.\",\n",
        "    \"license\": \"CC-BY-SA-4.0\",\n",
        "    \"tags\": [\"kubernetes\", \"documentation\", \"text\"],\n",
        "    \"language\": \"en\",\n",
        "    \"homepage\": \"https://example.com/dataset/kubernetes_documentation\",\n",
        "    \"citation\": \"Keerthika, Kubernetes Data, 2024.\",\n",
        "    \"version\": \"1.0.0\"\n",
        "}\n",
        "\n",
        "# Save dataset configuration to dataset_config.json\n",
        "config_file_path = os.path.join(dataset_dir, 'dataset_config.json')\n",
        "with open(config_file_path, 'w') as f:\n",
        "    json.dump(dataset_config, f, indent=4)\n",
        "\n",
        "# Copy your kubernetes_docs.txt file to the dataset directory (if not already there)\n",
        "# !cp /content/path_to_kubernetes_docs.txt /content/kubernetes_dataset/kubernetes_docs.txt\n"
      ],
      "metadata": {
        "id": "UqHovbh7rU00"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": [combined_kubernetes_text]})\n",
        "\n",
        "# Define the repository name (must be unique in your Hugging Face account)\n",
        "repo_name = \"kubernetes-documentation-dataset\"\n",
        "\n",
        "# Push dataset to the Hugging Face Hub\n",
        "dataset.push_to_hub(repo_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "efe8ac2aee25452ca461047b8dc12983",
            "963925742e31413eb4a8571f0e5a48dd",
            "5f2b346681324d2a8e96e27c03c04692",
            "3d1c314391d54b5fa77a67dc3b7a6dc7",
            "78175f4688104631b1ce86acb344f5e0",
            "a2fbec6aab3848cb966d69b4aa43d00e",
            "19c18a574d17483da0b54fd2dd0bdc32",
            "738a98bff6e04e34be3eae0f4a14ad89",
            "79e6a5aa05b44431bbacdfbb890e7028",
            "8f36031269664b8dbc57d945f6d4a13e",
            "d0e4b0cd7f8b4bd4b83eca32146f99c9",
            "e0f574705158487c84f7fea2798d1c9d",
            "5c24d741c6714bcc9010b89da6678e87",
            "b0af2c8f923f4d999fae8609ad3ac376",
            "a2cf03f77a8b4dc7889e37f282d2fbd0",
            "5e16d4dec18f4c6095f7da5af5bef3bd",
            "6c158572d56347faabd26947273e5ccb",
            "49c013ac21b24e50a354ff587ed8dae5",
            "5f0e70b4f9f54a0eaf124c83337950d7",
            "61851494cd8e447180a07f10f6b73a33",
            "df8d2879eb4b498584dd296fdeb9f7f1",
            "77f589f8753a430195777be571e52684"
          ]
        },
        "collapsed": true,
        "id": "kvprb75yuNZs",
        "outputId": "7a074be3-db4e-4a07-93eb-0ea95722ce42"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efe8ac2aee25452ca461047b8dc12983"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0f574705158487c84f7fea2798d1c9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/keethu/kubernetes-documentation-dataset/commit/01dd5fa5177a4765ce6c567c6272bdcd60a0bd09', commit_message='Upload dataset', commit_description='', oid='01dd5fa5177a4765ce6c567c6272bdcd60a0bd09', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence with the above codes we have successfully created the dataset, and now we shall be able to view the dataset created in the HuggingFace hub."
      ],
      "metadata": {
        "id": "VdUFdMHkv4hj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our Dataset ready, we shall perform some pre-processing over this Dataset."
      ],
      "metadata": {
        "id": "oyTDzOcLwese"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 2: Pre-processing the Data:"
      ],
      "metadata": {
        "id": "yCiPx5rnwom_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aiSaX8aKuAfZ",
        "outputId": "7d613fe1-abaa-4db9-ca53-418117262326"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# Read the text data\n",
        "file_path = '/content/kubernetes_dataset/kubernetes_docs.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "# Split text into chunks for better handling\n",
        "text_chunks = text_data.split('\\n\\n')\n",
        "\n",
        "# Tokenize text data\n",
        "tokenized_data = tokenizer(text_chunks, truncation=True, padding='max_length', max_length=512)\n",
        "\n"
      ],
      "metadata": {
        "id": "pgRx6Dxz3gOQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset from tokenized lists\n",
        "dataset = Dataset.from_dict({\n",
        "    'input_ids': input_ids,\n",
        "    'attention_mask': attention_mask\n",
        "})\n",
        "\n",
        "# Check dataset structure\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zpf5ihj36o_",
        "outputId": "bb6c9605-00d3-4eb8-9bf6-b75c60e9ccf5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask'],\n",
            "    num_rows: 1\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 3: Fine-tuning our data on the gpt2 model:"
      ],
      "metadata": {
        "id": "0-Up13Ek03m4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I initially started with the dataset pre-processing from scratch tho I had dataset updated in my hub, however I wasn't succesfull in doing so and hence I have loaded the dataset from the hub and fine tuned it on GPT.\n",
        "\n",
        "Method 1: Pre-processing and creation of Dataset from scratch.\n",
        "\n",
        "Method 2: Using Dataset I had loaded into the HF hub."
      ],
      "metadata": {
        "id": "jm63rqxZDB6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Method 1: Pre-processing and creation of Dataset from scratch."
      ],
      "metadata": {
        "id": "vBo0BYJZDkv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ixIhJ2Q1ACO",
        "outputId": "317c9c4e-e0d2-468a-d7d2-68390e9bd5e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask'],\n",
            "    num_rows: 1\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CpAGCoQc1H0r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KVn0STzt1RND",
        "outputId": "64c5dd93-af33-4ab3-df03-b272a2a05fe4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "\n",
        "# Load GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Define data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,  # Adjust based on your GPU capacity\n",
        "    save_steps=5_000,\n",
        "    save_total_limit=2,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        ")"
      ],
      "metadata": {
        "id": "pdKEIl1l4TBR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['input_ids'][0], dataset['attention_mask'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FDyJiSBF6Zqz",
        "outputId": "c0e34714-74f8-4c09-c45e-35f75e576f75"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([36674,\n",
              "  2420,\n",
              "  422,\n",
              "  12554,\n",
              "  527,\n",
              "  3262,\n",
              "  274,\n",
              "  10314,\n",
              "  13,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257,\n",
              "  50257],\n",
              " [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# Initialize Trainer with the full dataset\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "try:\n",
        "    trainer.train()\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "    # Optionally, inspect the dataset sample for debugging\n",
        "    print(\"Sample input_ids:\", dataset['input_ids'][0])\n",
        "    print(\"Sample attention_mask:\", dataset['attention_mask'][0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KCS7MhM619Ad",
        "outputId": "ff5a3679-4d52-4f95-a460-b4e07e920fe3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during training: index out of range in self\n",
            "Sample input_ids: [36674, 2420, 422, 12554, 527, 3262, 274, 10314, 13, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]\n",
            "Sample attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since I have recieved an error, I shall try loading the dataset from HF hub and use it to fine tune."
      ],
      "metadata": {
        "id": "vtRZHpGo7QaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Method 2: Using Dataset I had loaded into the HF hub."
      ],
      "metadata": {
        "id": "D51hP_K6DtYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "ds = load_dataset(\"keethu/kubernetes-documentation-dataset\")\n",
        "\n",
        "# Step 2: Tokenize the dataset\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
        "\n",
        "tokenized_datasets = ds.map(tokenize_function, batched=True)\n",
        "\n",
        "# Step 3: Prepare for training\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',  # Provide a directory to save the trained model and logs\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    eval_strategy=\"no\",  # No evaluation during training\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zlQlxwRG7Zmp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "# Step 4: Fine-tune the model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "collapsed": true,
        "id": "F8XMaDVSBIwX",
        "outputId": "f5127483-4f36-4e50-ce8e-4b70cf6bfdad"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:52, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=3.4602108001708984, metrics={'train_runtime': 83.5107, 'train_samples_per_second': 0.036, 'train_steps_per_second': 0.036, 'total_flos': 1567752192000.0, 'train_loss': 3.4602108001708984, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}